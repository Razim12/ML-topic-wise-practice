{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_log_error,mean_squared_error,roc_auc_score\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import SGDRegressor,LinearRegression,Lasso,Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from math import sqrt\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/Data_Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['Unique_ID','Country','Name'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.get_dummies(data,columns=['Genre'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Timestamp'] =pd.to_datetime(data['Timestamp'])\n",
    "data['dayofweek'] = data['Timestamp'].dt.dayofweek #but mostly people on weekend\n",
    "data['weekend'] = data['dayofweek'].apply(lambda x: 1 if (x>4)  else 0)\n",
    "display(data.groupby(['dayofweek'])['Views'].mean())\n",
    "display(data.groupby(['weekend'])['Views'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()\n",
    "#if mean and median not equal outliers ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(data, alpha=0.3, figsize=(14,8), diagonal='kde');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.regplot(x=\"Likes\", y=\"Views\", data=data)\n",
    "#sns.regplot(x=\"Comments\", y=\"Views\", data=data)\n",
    "#sns.regplot(x=\"Popularity\", y=\"Views\", data=data)\n",
    "sns.regplot(x=\"Followers\", y=\"Views\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularityConverting(x):\n",
    "    if x[-1]=='K':\n",
    "        x= ''.join(x[:-1].split(','))\n",
    "        x=float(x)*1000\n",
    "    elif x[-1]=='M':\n",
    "        x= ''.join(x[:-1].split(','))\n",
    "        x=float(x)*1000000\n",
    "    else:\n",
    "        x= ''.join(x.split(','))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Popularity'] = data.Popularity.apply(popularityConverting)\n",
    "data['Popularity'] = data.Popularity.astype('float')\n",
    "data['Likes'] = data.Likes.apply(popularityConverting)\n",
    "data['Likes'] = data.Likes.astype('float')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(text):\n",
    "    \n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = [word for word in text.split() if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    return \" \".join(text)\n",
    "data['Song_Name']=data['Song_Name'].astype('str')\n",
    "data['Song_Name'] = data['Song_Name'].apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Song_Name'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying for time as feature\n",
    "display(data[data['Timestamp']==data['Timestamp'].min()])\n",
    "display(data[data['Timestamp']==data['Timestamp'].max()])\n",
    "data.sort_values(by=['Timestamp']).groupby(['Timestamp'])['Views'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_data =data.loc[:,['Comments', 'Likes', 'Popularity', 'Followers','weekend']]\n",
    "X = data.loc[:,['Comments', 'Likes', 'Popularity', 'Followers','weekend']]\n",
    "y = data['Views']\n",
    "X= StandardScaler().fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(data.loc[:,['Views','Comments', 'Likes', 'Popularity', 'Followers','weekend']], alpha=0.3, figsize=(14,8), diagonal='kde');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build PCA using standarized trained data\n",
    "pca = PCA(n_components=None, svd_solver=\"full\")\n",
    "pca.fit(StandardScaler().fit_transform(X_train))\n",
    "print(pca.explained_variance_ratio_)\n",
    "cum_var_exp = np.cumsum(pca.explained_variance_ratio_)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(1, 6), pca.explained_variance_ratio_, align=\"center\",\n",
    "        color='red', label=\"Individual explained variance\")\n",
    "plt.step(range(1, 6), cum_var_exp, where=\"mid\", label=\"Cumulative explained variance\")\n",
    "plt.xticks(range(1, 6))\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"Principal component index\", {\"fontsize\": 14})\n",
    "plt.ylabel(\"Explained variance ratio\", {\"fontsize\": 14})\n",
    "plt.title(\"PCA on training data\", {\"fontsize\": 16});\n",
    "print(cum_var_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_regressor =LinearRegression()\n",
    "lr_regressor.fit(X_train, y_train)\n",
    "preds = lr_regressor.predict(X_test)\n",
    "plt.scatter(y_test,preds)\n",
    "plt.grid()\n",
    "plt.xlabel('Actual y')\n",
    "plt.ylabel('Predicted y')\n",
    "plt.title('scatter plot between actual y and predicted y')\n",
    "plt.show()\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_params = {'alpha':[0.005,0.001, 0.02, 0.03, 0.05, 0.06]}\n",
    "laso_regressor=Lasso()\n",
    "laso_regressor_cv=GridSearchCV(laso_regressor,lasso_params,cv=5)\n",
    "laso_regressor_cv.fit(X,y)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",laso_regressor_cv.best_params_)\n",
    "print(\"accuracy :\",laso_regressor_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laso_regressor =Lasso(alpha= 0.001)\n",
    "laso_regressor.fit(X_train, y_train)\n",
    "preds = laso_regressor.predict(X_test)\n",
    "plt.scatter(y_test,preds)\n",
    "plt.grid()\n",
    "plt.xlabel('Actual y')\n",
    "plt.ylabel('Predicted y')\n",
    "plt.title('scatter plot between actual y and predicted y')\n",
    "plt.show()\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_regressor= RandomForestRegressor()\n",
    "hyperparam_grid={\"n_estimators\": [10, 50, 100],\"max_features\": [\"sqrt\", \"log2\", 0.4, 0.5],\\\n",
    "                 \"min_samples_leaf\": [1, 3, 5]}\n",
    "rf_regressor_cv = GridSearchCV(rf_regressor,hyperparam_grid,cv=2)\n",
    "rf_regressor_cv.fit(X,y)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",rf_regressor_cv.best_params_)\n",
    "print(\"accuracy :\",rf_regressor_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_regressor=RandomForestRegressor(max_features= 0.4, min_samples_leaf= 1, n_estimators=100)\n",
    "rf_regressor.fit(X_train,y_train)\n",
    "\n",
    "preds = rf_regressor.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "plt.scatter(y_test,preds)\n",
    "plt.grid()\n",
    "plt.xlabel('Actual y')\n",
    "plt.ylabel('Predicted y')\n",
    "plt.title('scatter plot between actual y and predicted y')\n",
    "plt.show()\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = rf_regressor.feature_importances_\n",
    "print(np.argsort(rf_regressor.feature_importances_))\n",
    "indices = np.argsort(rf_regressor.feature_importances_)[::-1]\n",
    "print(indices)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.xticks(range(1, 6), features_data.columns[indices], rotation=90)\n",
    "plt.bar(range(1, 6), feature_importance[indices], align=\"center\")\n",
    "plt.title(\"Feature Importance\", {\"fontsize\": 16});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_regressor=xgb.XGBRegressor()\n",
    "\n",
    "n_estimators = [100, 500]\n",
    "max_depth = [2, 3, 5, 10, 15]\n",
    "learning_rate=[0.05,0.1,0.15,0.20]\n",
    "min_child_weight=[1,2,3,4]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    }\n",
    "\n",
    "# Set up the random search with 4-fold cross validation\n",
    "xgb_regressor_cv = RandomizedSearchCV(estimator=xgb_regressor,\n",
    "            param_distributions=hyperparameter_grid,\n",
    "            cv=2,\n",
    "            scoring = 'neg_mean_absolute_error',\n",
    "            return_train_score = True,\n",
    "            random_state=42)\n",
    "xgb_regressor_cv.fit(X_train,y_train)\n",
    "xgb_regressor_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regressor=xgb.XGBRegressor(objective ='reg:squarederror',n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.1, booster='gbtree', base_score=0.25)\n",
    "xgb_regressor= xgb.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
    "             importance_type='gain', learning_rate=0.15, max_delta_step=0,\n",
    "             max_depth=10, min_child_weight=1, missing=None, n_estimators=500,\n",
    "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "             silent=None, subsample=1, verbosity=1)\n",
    "xgb_regressor.fit(X_train,y_train)\n",
    "\n",
    "preds = xgb_regressor.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "plt.scatter(y_test,preds)\n",
    "plt.grid()\n",
    "plt.xlabel('Actual y')\n",
    "plt.ylabel('Predicted y')\n",
    "plt.title('scatter plot between actual y and predicted y')\n",
    "plt.show()\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outliers\n",
    "xgb_regressor.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = xgb_regressor.feature_importances_\n",
    "print(np.argsort(xgb_regressor.feature_importances_))\n",
    "indices = np.argsort(xgb_regressor.feature_importances_)[::-1]\n",
    "print(indices)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.xticks(range(1, 6), features_data.columns[indices], rotation=90)\n",
    "plt.bar(range(1, 6), feature_importance[indices], align=\"center\")\n",
    "plt.title(\"Feature Importance\", {\"fontsize\": 16});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {\"Linear Regressor\": lr_regressor,\n",
    "              \"Lasso Regressor\": laso_regressor,\n",
    "              \"Random Forest Regressor\": rf_regressor,\n",
    "              \"XGB Regressor\": xgb_regressor}\n",
    "for estimator in estimators.keys():\n",
    "    print('RMSE {}:{:.2f}'.format(estimator,np.sqrt(mean_squared_error(y_test, estimators[estimator].predict(X_test)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('./Data_Test.csv')\n",
    "display(data_test.head())\n",
    "label= data_test['Unique_ID']\n",
    "data_test.drop(columns=['Unique_ID','Country','Name','Song_Name'],axis=1,inplace=True)\n",
    "data_test['Timestamp'] =pd.to_datetime(data_test['Timestamp'])\n",
    "data_test['dayofweek'] = data_test['Timestamp'].dt.dayofweek #but mostly people on weekend\n",
    "data_test['weekend'] = data_test['dayofweek'].apply(lambda x: 1 if (x>4)  else 0)\n",
    "display(data_test.head())\n",
    "data_test['Popularity'] = data_test.Popularity.apply(popularityConverting)\n",
    "data_test['Popularity'] = data_test.Popularity.astype('float')\n",
    "data_test['Likes'] = data_test.Likes.apply(popularityConverting)\n",
    "data_test['Likes'] = data_test.Likes.astype('float')\n",
    "X_testf = data_test.loc[:,['Comments', 'Likes', 'Popularity', 'Followers','weekend']]\n",
    "#y_testf = data['Views']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testf= StandardScaler().fit(X_testf).transform(X_testf)\n",
    "display(len(X_testf))\n",
    "Y_pred = xgb_regressor.predict(X_testf)\n",
    "display(len(Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_pred)\n",
    "display(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_excel('./Sample_Submission.xlsx') \n",
    "submission = pd.DataFrame({\n",
    "        \"Unique_ID\": label,\n",
    "        \"Views\": Y_pred\n",
    "    })\n",
    "submission.to_excel('./Sample_Submission_Final.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.wrappers.scikit_learn import KerasClassifier,KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create mode\n",
    "    model = Sequential()\n",
    "    model.add(Dense( units=12, input_dim=5, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense( units=8, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(units = 1, kernel_initializer='he_uniform'))\n",
    "    # Compile model\n",
    "    model.compile(loss=root_mean_squared_error, optimizer='Adamax')\n",
    "    return model\n",
    "# create model\n",
    "model = KerasRegressor(build_fn=create_model)\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=model.fit(X_train, y_train,validation_split=0.30, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, ann_pred))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
