{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOXIC COMMENT CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import hamming_loss,accuracy_score,log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import necessary files\n",
    "df = pd.read_csv('./data/jigsaw-toxic-comment-classification-challenge/train.csv')\n",
    "df =df.iloc[:15000,:]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the fields in our dataframe\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we have a sufficiently large dataset consistly of 95851 samples. Each sample contains 8 fields.\n",
    "#### It was observed that running train_test_split on the heavy preprocessed dataframe sometimes resulted in system going out of memory. Hence to avoid such cases, one extra line of code was added. The df.reindex code will shuffle the indices initially, so that later splitting dataset into training and testing will give fairer results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below line causes shuffling of indices, to avoid using train_test_split later\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "#rearranging datafram columns indexes based param , it can be df.max/min whatevr order here we are doing randomly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate the comment field data and outcome labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = df['comment_text']\n",
    "print(comment.head())\n",
    "comment = comment.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df[['toxic', 'severe_toxic' , 'obscene' , 'threat' , 'insult' , 'identity_hate']]\n",
    "print(label.head())\n",
    "label = label.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### frequency of occurence of multilabelled data\n",
    "ct1 counts samples having atleast one label\n",
    "ct2 counts samples having 2 or more than 2 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct1,ct2 = 0,0\n",
    "for i in range(label.shape[0]):\n",
    "    ct = np.count_nonzero(label[i])\n",
    "    if ct :\n",
    "        ct1 = ct1+1\n",
    "    if ct>1 :\n",
    "        ct2 = ct2+1\n",
    "print(ct1)\n",
    "print(ct2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualisations\n",
    "\n",
    "no. of comments having lengths varying from 0 to 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [len(comment[i]) for i in range(comment.shape[0])]\n",
    "\n",
    "print('average length of comment: {:.3f}'.format(sum(x)/len(x)) )\n",
    "bins = [1,200,400,600,800,1000,1200]\n",
    "plt.hist(x, bins=bins)\n",
    "plt.xlabel('Length of comments')\n",
    "plt.ylabel('Number of comments')       \n",
    "plt.axis([0, 1200, 0, 90000])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Number of comments classified as toxic,severe_toxic,....etc depending on their lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros(label.shape)\n",
    "for ix in range(comment.shape[0]):\n",
    "    l = len(comment[ix])\n",
    "    if label[ix][0] :\n",
    "        y[ix][0] = l\n",
    "    if label[ix][1] :\n",
    "        y[ix][1] = l\n",
    "    if label[ix][2] :\n",
    "        y[ix][2] = l\n",
    "    if label[ix][3] :\n",
    "        y[ix][3] = l\n",
    "    if label[ix][4] :\n",
    "        y[ix][4] = l\n",
    "    if label[ix][5] :\n",
    "        y[ix][5] = l\n",
    "\n",
    "labelsplt = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "color = ['red','green','blue','yellow','orange','chartreuse']        \n",
    "plt.hist(y,bins = bins,label = labelsplt,color = color)\n",
    "plt.axis([0, 1200, 0, 8000])\n",
    "plt.xlabel('Length of comments')\n",
    "plt.ylabel('Number of comments') \n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove excessive length comments\n",
    "Some very large length comments can be seen, in our dataset. These pose serious problems like adding excessively more words to the training dataset, causing training time to increase and accuracy to decrease!\n",
    "Hence, a threshold of 400 characters will be created and only comments which have length smaller than 400 will be used further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "comments = []\n",
    "labels = []\n",
    "\n",
    "for ix in range(comment.shape[0]):\n",
    "    if len(comment[ix])<=400:\n",
    "        comments.append(comment[ix])\n",
    "        labels.append(label[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "#### Preprocessing involved the following steps, but these will be performed in a slightly different manner:\n",
    "\n",
    "- Removing Punctuations and other special characters\n",
    "- Splitting the comments into individual words\n",
    "- Removing Stop Words \n",
    "- Stemming and Lemmatising\n",
    "- Applying Count Vectoriser\n",
    "- Splitting dataset into Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The string library contains punctuation characters. This is imported and all numbers are appended to this string. Also, we can notice that our comment_text field contains strings such as won't, didn't, etc which contain apostrophe character('). To prevent these words from being converted to wont/didnt, the character ' represented as \\' in escape sequence notation is replaced by empty character in the punctuation string.\n",
    "\n",
    "maketrans() returns a translation table that maps each character in the punctuation_edit into the character at the same position in the outtab string i.e. it replaces every character in the removal list with a space, since outtab contains a string with spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "print(string.punctuation)\n",
    "punctuation_edit = string.punctuation.replace('\\'','') +\"0123456789\"\n",
    "print (punctuation_edit)\n",
    "outtab = \"                                         \"\n",
    "trantab = str.maketrans(punctuation_edit, outtab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop words are those words that are frequently used in both written and verbal communication and thereby do not have either a positive/negative impact on our statement.E.g. is, this, us,etc.\n",
    "Single letter words if existing or created due to any preprocessing step do not convey any useful meaning and hence can be directly removed. Hence letters from b to z, will be added to the list of stop words imported directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.append('')\n",
    "\n",
    "for x in range(ord('b'), ord('z')+1):\n",
    "    stop_words.append(chr(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stemming is the process of converting inflected/derived words to their word stem or the root form. Basically, a large number of similar origin words are converted to the same word.E.g. words like \"stems\", \"stemmer\", \"stemming\", \"stemmed\" as based on \"stem\". This helps in achieving the training process with a better accuracy.\n",
    "- Lemmatizing is the process of grouping together the inflected forms of a word so they can be analysed as a single item. This is quite similar to stemming in its working but differs since it depends on correctly identifying the intended part of speech and meaning of a word in a sentence, as well as within the larger context surrounding that sentence, such as neighboring sentences or even an entire document.\n",
    "The wordnet library in nltk will be used for this purpose. Stemmer and Lemmatizer are also imported from nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create objects for stemmer and lemmatizer\n",
    "lemmatiser = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "#download words from wordnet library\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(comments)):\n",
    "    comments[i] = comments[i].lower().translate(trantab)\n",
    "    l = []\n",
    "    for word in comments[i].split():\n",
    "        l.append(stemmer.stem(lemmatiser.lemmatize(word,pos=\"v\")))\n",
    "    comments[i] = \" \".join(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying Count Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required library\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#create object supplying our custom stop words\n",
    "count_vector = CountVectorizer(stop_words=stop_words)\n",
    "#fitting it to converts comments into bag of words format\n",
    "tf = count_vector.fit_transform(comments).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(count_vector.get_feature_names())\n",
    "print(tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting dataset into training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since the system was going out of memory using train_test_split, I had jumbled all the indexes in the beginning itself.\n",
    "- The shuffle function defined here performs the task of assigning first 2/3rd values to train and remaining 1/3rd values to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(matrix, target, test_proportion):\n",
    "    ratio = int(matrix.shape[0]/test_proportion)\n",
    "    X_train = matrix[ratio:,:]\n",
    "    X_test =  matrix[:ratio,:]\n",
    "    Y_train = target[ratio:,:]\n",
    "    Y_test =  target[:ratio,:]\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = shuffle(tf, labels,3)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the evaluation metrics\n",
    "def evaluate_score(Y_test,predict): \n",
    "    loss = hamming_loss(Y_test,predict)\n",
    "    print(\"Hamming_loss : {}\".format(loss*100))\n",
    "    accuracy = accuracy_score(Y_test,predict)\n",
    "    print(\"Accuracy : {}\".format(accuracy*100))\n",
    "    try : \n",
    "        loss = log_loss(Y_test,predict)\n",
    "    except :\n",
    "        loss = log_loss(Y_test,predict.toarray())\n",
    "    print(\"Log_loss : {}\".format(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Transformation Methods :\n",
    "These include the Binary Relevance, Label Powerset and Classifier Chain methods. Implementations of these methods is available in the scikit-multilearn library.\n",
    "\n",
    "- I will be implementing the most basic method,which is the Binary Relevance method from scratch. It does not take into account the interdependence of labels and basically creates a separate classifier for each of the labels.\n",
    "- Scikit-multilearn library's classifier will also be imported and tested with different classifiers to observe if it gives similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each classifier is fit with the training data and corresponding classifier\n",
    "clf = []\n",
    "for ix in range(6):\n",
    "    clf.append(MultinomialNB())\n",
    "    clf[ix].fit(X_train,Y_train[:,ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# predict list contains the predictions, it is transposed later to get the proper shape\n",
    "predict = []\n",
    "for ix in range(6):\n",
    "    predict.append(clf[ix].predict(X_test))\n",
    "\n",
    "predict = np.asarray(np.transpose(predict))\n",
    "print(predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate results\n",
    "evaluate_score(Y_test,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
